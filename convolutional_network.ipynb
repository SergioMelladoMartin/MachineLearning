{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHXmeDm-S27W"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eGAPs5nS27Y"
      },
      "outputs": [],
      "source": [
        "# Cargar el conjunto de datos MNIST con metadatos\n",
        "data, metadata = tfds.load('mnist', as_supervised=True, with_info=True)\n",
        "\n",
        "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "train_data, test_data = data['train'], data['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir una función para normalizar las imágenes y las etiquetas\n",
        "def normalize(images, labels):\n",
        "  images = tf.cast(images, tf.float32)\n",
        "  images /= 255 \n",
        "  return images, labels\n",
        "\n",
        "# Normalizar los datos de entrenamiento y prueba utilizando la función de normalización\n",
        "train_data = train_data.map(normalize)\n",
        "test_data = test_data.map(normalize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir la arquitectura del modelo\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), input_shape=(28,28,1), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=100, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo con optimizador, función de pérdida y métricas\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener el número de puntos de datos de entrenamiento y prueba\n",
        "num_train_examples = metadata.splits[\"train\"].num_examples\n",
        "num_test_examples = metadata.splits[\"test\"].num_examples\n",
        "\n",
        "# Definir el tamaño del lote\n",
        "BATCH_SIZE=32\n",
        "\n",
        "# Mezclar y repetir los datos de entrenamiento\n",
        "train_data = train_data.repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "test_data = test_data.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar el modelo\n",
        "import math\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=5,\n",
        "    steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE)\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "72314bc56fbc7c30f6ddfe32e65ca0443b82f67edb55fdb2a67ef671e06fe13b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
